---
title: Model Predictive Control (MPC) as Process Control Method
date: "2021-04-01"
blogID: "00051"
tags: ["NPU", "Hidden"]
draft: false
summary: Model Predictive Control (MPC) as Process Control Method
coverImage: "/static/blog/00001.png"
embedId: ""
---

## Model Predictive Control (MPC) as Process Control Method

### Github Repo (Code & Report)

[Python Code](https://github.com/HassanAMZ/Model-Predictive-Control-Process-Control-Method)

Optimal control is a method to use model predictions to plan an optimized future trajectory for time-varying systems. It is often referred to as Model Predictive Control (MPC) or Dynamic Optimization.

A method to solve dynamic control problems is by numerically integrating the dynamic model at discrete time intervals, much like measuring a physical system at time points. The numerical solution is compared to the desired trajectory and the difference is minimized by adjustable parameters in the model that may change at every time step. The first control action is taken and then the entire process is repeated at the next instance. The process is repeated because objective targets may change, or updated measurements may have adjusted parameter or state estimates.

Model predictive control has a number of manipulated variable (MV) and controlled variable (CV) tuning constants. The tuning constants are terms in the optimization objective function that can be adjusted to achieve the desired application performance.

Model predictive control uses a mathematical model to optimize and control a system. For example, we have a vehicle that we want to have gone from zero up to a speed of 40 m/s and we are going to adjust the gas pedal and the power to the accelerator, and we would normally do that as we are entering onto a freeway. We normally increase the gas pedal or the accelerator pedal and then after we get up to speed, we back off just enough to maintain that speed, so we have an acceleration phase. Then our steady-state phase we want an optimizer to do that for us instead of us doing it will have an optimizer just as each of those manipulated variables moves all along the way until it produces an optimal profile that helps us keep along the desired trajectory.

![Figure 1](/static/blog/00051_1.png)

So this is called a reference trajectory and it describes how we want the controlled variable to behave so that our output is the controlled variable and we're telling it the objective now we're going to use a couple of things here we're going to use a mathematical model of this system and then also known limitations on our manipulated variable or other constraints that we want to impose and then we'll solve an optimization problem.

Let us set that up in Gecko we are going to solve this optimization problem with and just set it up and solve it with Gecko. So, the very first thing we would need to do is just to import the gecko. We also do random and matplotlib and as pipe lot and they don't forget the percent map pilot in line and then have M = gecko and then we'll set up our time horizon so our time horizon is how far and how frequently we're going to look forward into the future with our mathematical model and for the optimizer to plan a prediction horizon.

We have some parameters we have mass we have our gain k and then we are going to move on down to the manipulated variable definition which is our gas pedal or accelerator pedal. I'm just going to call P and we can go between zero and a hundred so we have a lower bound of zero and upper bound of 100 and then we're going to turn its status on so status allows the optimizer to change that value if we have it as an FB that it just has one value over the whole horizon. If we have an MV then it is able to change that at every time point on the horizon. Add D cost i.e., delta cost and describe this in the objective we are penalizing the manipulated variable movement so if we have a small cost there, we can often smooth out the manipulated variable a little bit more.

<video src='/static/blog/00051_2.mp4' controls='controls'></video>

If we have zero, then all it is concerned about is meeting that trajectory so that the T value that Y of T then we put a certain waiting on that, so this is in the squared air from that reference trajectory. We also have a couple of other tuning parameters we deal with d-max that deal with how much we can move the manipulated variable each cycle, so we saw 0.5 second cycles. So, it can move it to a total of in this case 20 percent and the next cycle can go up to forty at the most.

Then we have our controlled variable as well I'm just going to find the velocity and we have it status equal to 1 the initial value is equal to 0 and then I have CV type is - that's our square - air so we could either have a squared air or we could have something like an l1 norm we know for a reference trajectory with a dead band so here's our squared air right here and then if we wanted to implement the l1 norm we would just be these two terms right here that are defined by these inequalities and they're just the air as we get outside of the trajectory dead band.

An l1 norm might be something like this where we say go within that region and then it would try to maintain this CV value within that region but we're just going to use a standard square - air formulation and we could also say let's say I just wanted to say my trajectory is equal to 40 we could tell it to try to get there as fast as we could.

A lot of different options for reference trajectories but in this case we're just going to use a squared error which is CV type - there's our set point which is equal to 40 and our trajectory initialization this is equal to 1 that means start from where we are right here and go up with a certain time constant to the new value the time constant in this case is going to be 5 so it's going to get about 63 percent of the way there at five seconds. That's our time constant for the reference trajectory we know we have a process model there's just a simple differential equation it can be any differential and algebraic equations non-linear or linear equations there's a mode six that's for control and then we'll solve the problems now we've set up and solve this optimization problem the next part is just going to be plotting and retrieving some values let's say we want to get the reference trajectory that isn't reported with the standard solution I'm just going to import JSON and then I'll open the results dot JSON file and then we'll get that with results.

It just signs it to the variable results then we'll plot our figure this one's going to be just the first subplot and that's going to be MV optimized we'll put on a legend and we'll give it a wire level as well so we can see that there at the bottom we also have subplot two which we're going to use the the JSON file that we just imported the results we're going to get the trajectory value from that and it'll plot that as a black line and then we'll also get the CB response which is going to be a red dashed line and then we'll give it a y label an X label and our legend and it will also save the figure export as a PNG transparent background with dots per inch equals to 600 so high resolution version.

There is our moving horizon estimation solution let me go and just run this and one of the important things with moving her eyes estimation it must be fast enough to be able to solve real time so if I say display equals true on the solver output. We can see fourteen iterations and it found the solution in under 0.1 seconds so point zero six seconds.

That is the demonstration of moving out of this is model predictive control I'll just show we for example TR NIT if I set that equal to zero that's just going to be a pure set point no reference trajectory let me go and turn off the display there so we don't get the solver output and that's going to have a pure reference trajectory that's going to just go up to 40.

Then we can set other options as well we had so for example if we wanted to go faster I'll set this back to trajectory initialization of one we could say I want to go faster up to that set point so we can see it's right here it's limited by the we know that just the dynamics of the system so it can't meet that reference trajectory but we can see that the manipulated variable is saturated so that is as fast as it can go so manipulated variable is already at 100.

This was a tutorial on model predictive control. We can set this up to solve it in a loop we know every certain cycle time we would get new measurements for controlled variables and then based on that we would replan manipulated variable path we would implement just the very first manipulated variable. The point 0.5 seconds we take a new measurement and then we would reoptimize implementing that next one and continue like that just implementing just the first one in that cycle and we would have a model predictive controller that would be able to control a real process.

### Python Code

```python
import numpy as np
import matplotlib.pyplot as plt
import time
from scipy.integrate import odeint
from scipy.optimize import minimize

# Make an MP4 animation?
make_mp4 = False
if make_mp4:
    import imageio  # required to make animation
    import os
    try:
        os.mkdir('./figures')
    except:
        pass

# Define process model
def process_model(y,t,u,K,tau):
    # arguments
    #  y   = outputs
    #  t   = time
    #  u   = input value
    #  K   = process gain
    #  tau = process time constant

    # calculate derivative
    dydt = (-y + K * u)/(tau)

    return dydt

# Define Objective function
def objective(u_hat):
    # Prediction
    for k in range(1,2*P+1):
        if k==1:
            y_hat0 = yp[i-P]

        if k<=P:
            if i-P+k<0:
                u_hat[k] = 0

            else:
                u_hat[k] = u[i-P+k]

        elif k>P+M:
            u_hat[k] = u_hat[P+M]

        ts_hat = [delta_t_hat*(k-1),delta_t_hat*(k)]
        y_hat = odeint(process_model,y_hat0,ts_hat,args=(u_hat[k],K,tau))
        y_hat0 = y_hat[-1]
        yp_hat[k] = y_hat[0]

        # Squared Error calculation
        sp_hat[k] = sp[i]
        delta_u_hat = np.zeros(2*P+1)

        if k>P:
            delta_u_hat[k] = u_hat[k]-u_hat[k-1]
            se[k] = (sp_hat[k]-yp_hat[k])**2 + 20 * (delta_u_hat[k])**2

    # Sum of Squared Error calculation
    obj = np.sum(se[P+1:])
    return obj

# FOPDT Parameters
K=3.0      # gain
tau=5.0    # time constant
ns = 100    # Simulation Length
t = np.linspace(0,ns,ns+1)
delta_t = t[1]-t[0]

# Define horizons
P = 30 # Prediction Horizon
M = 10  # Control Horizon

# Input Sequence
u = np.zeros(ns+1)

# Setpoint Sequence
sp = np.zeros(ns+1+2*P)
sp[10:40] = 5
sp[40:80] = 10
sp[80:] = 3
# Controller setting
maxmove = 1

## Process simulation
yp = np.zeros(ns+1)

#  Create plot
plt.figure(figsize=(10,6))
plt.ion()
plt.show()

for i in range(1,ns+1):
    if i==1:
        y0 = 0
    ts = [delta_t*(i-1),delta_t*i]
    y = odeint(process_model,y0,ts,args=(u[i],K,tau))
    y0 = y[-1]
    yp[i] = y[0]

    # Declare the variables in fuctions
    t_hat = np.linspace(i-P,i+P,2*P+1)
    delta_t_hat = t_hat[1]-t_hat[0]
    se = np.zeros(2*P+1)
    yp_hat = np.zeros(2*P+1)
    u_hat0 = np.zeros(2*P+1)
    sp_hat = np.zeros(2*P+1)
    obj = 0.0

    # initial guesses
    for k in range(1,2*P+1):

        if k<=P:
            if i-P+k<0:
                u_hat0[k] = 0

            else:
                u_hat0[k] = u[i-P+k]

        elif k>P:
            u_hat0[k] = u[i]

    # show initial objective
    print('Initial SSE Objective: ' + str(objective(u_hat0)))

    # MPC calculation
    start = time.time()

    solution = minimize(objective,u_hat0,method='SLSQP')
    u_hat = solution.x

    end = time.time()
    elapsed = end - start

    print('Final SSE Objective: ' + str(objective(u_hat)))
    print('Elapsed time: ' + str(elapsed) )

    delta = np.diff(u_hat)

    if i<ns:
        if np.abs(delta[P]) >= maxmove:
            if delta[P] > 0:
                u[i+1] = u[i]+maxmove
            else:
                u[i+1] = u[i]-maxmove

        else:
            u[i+1] = u[i]+delta[P]

    # plotting for forced prediction
    plt.clf()
    plt.subplot(2,1,1)
    plt.plot(t[0:i+1],sp[0:i+1],'r-',linewidth=2,label='Setpoint')
    plt.plot(t_hat[P:],sp_hat[P:],'r--',linewidth=2)
    plt.plot(t[0:i+1],yp[0:i+1],'k-',linewidth=2,label='Measured CV')
    plt.plot(t_hat[P:],yp_hat[P:],'k--',linewidth=2,label='Predicted CV')
    plt.axvline(x=i,color='gray',alpha=0.5)
    plt.axis([0, ns+P, 0, 12])
    plt.ylabel('y(t)')
    plt.legend()
    plt.subplot(2,1,2)
    plt.step(t[0:i+1],u[0:i+1],'b-',linewidth=2,label='Measured MV')
    plt.plot(t_hat[P:],u_hat[P:],'b.-',linewidth=2,label='Predicted MV')
    plt.axvline(x=i,color='gray',alpha=0.5)
    plt.ylabel('u(t)')
    plt.xlabel('time')
    plt.axis([0, ns+P, 0, 6])
    plt.legend()
    plt.draw()
    plt.pause(0.1)
    if make_mp4:
        filename='./figures/plot_'+str(i+10000)+'.png'
        plt.savefig(filename)

# generate mp4 from png figures in batches of 350
if make_mp4:
    images = []
    iset = 0
    for i in range(1,ns):
        filename='./figures/plot_'+str(i+10000)+'.png'
        images.append(imageio.imread(filename))
        if ((i+1)%350)==0:
            imageio.mimsave('results_'+str(iset)+'.mp4', images)
            iset += 1
            images = []
    if images!=[]:
        imageio.mimsave('results_'+str(iset)+'.mp4', images)



```
